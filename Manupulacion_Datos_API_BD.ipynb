{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos las Librerias a Trabajar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import date,datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from pansql import sqldf\n",
    "import teradatasql\n",
    "import logging\n",
    "import holidays_co\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tomar la Fecha del sistema con el fin de crear una carpeta de manera local en donde se guardarn el Log y los archivos de Salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The code you provided is creating a folder with a specific name based on the current date and time.\n",
    "titulo = \"Resumen por Fecha\"\n",
    "\n",
    "now = datetime.now()\n",
    "if now.day<10:\n",
    "    dia = \"0\"+str(now.day)\n",
    "else:\n",
    "    dia = str(now.day)\n",
    "\n",
    "if now.month<10:\n",
    "    mes = \"0\"+str(now.month)\n",
    "else:\n",
    "    mes = str(now.month)\n",
    "\n",
    "NombreCarpeta = dia + mes + str(now.year)+'_D'\n",
    "\n",
    "ubicacion_fija = os.getcwd()\n",
    "ruta_carpeta = os.path.join(ubicacion_fija, NombreCarpeta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que la Carpeta no este creada en la ubicacion deseada de lo contrario la creaara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is creating a folder (directory) in the current working directory.\n",
    "ubicacion_fija = os.getcwd()\n",
    "ruta_carpeta = os.path.join(ubicacion_fija, NombreCarpeta)\n",
    "\n",
    "if not os.path.exists(ruta_carpeta):\n",
    "    os.makedirs(ruta_carpeta)\n",
    "    print(f\"Carpeta '{NombreCarpeta}' creada en '{ubicacion_fija}'\")\n",
    "else:\n",
    "    print(f\"La carpeta '{NombreCarpeta}' ya existe en '{ubicacion_fija}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos los dias feriados de los años 2023 y 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The code snippet is creating a list of years `[2023, 2024]` and then iterating over each year to retrieve the holidays in Colombia for that year using the `holidays_co.get_colombia_holidays_by_year()` function. The holidays for each year are stored in the `days` list.\n",
    "years = [2023,2024]\n",
    "days = []\n",
    "for i in years:\n",
    "    days.append(holidays_co.get_colombia_holidays_by_year(i))\n",
    "\n",
    "holydays = []\n",
    "for i in range(len(days)):\n",
    "    for j in range(len(days[i])):\n",
    "        holydays.append(days[i][j][0]) \n",
    "\n",
    "NomArchivo_log =       ruta_carpeta+'\\\\'+ dia + mes + str(now.year) +\"Validacion.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear una Funcion la cual permitiria la coneccion a la base de datos, para este caso se creo una conexio a la base Denominada Teradata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The code defines a function called `conexion` that takes four parameters: `host`, `user`, `password`, and `query`.\n",
    "def Connection_TeraData(host, user, password, query):\n",
    "    try:\n",
    "        conn = teradatasql.connect(host=host, user=user, password=password)       \n",
    "        df = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        return df\n",
    "\n",
    "    except Exception as e:       \n",
    "        print(f\"Error de conexión: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crear una funcion que consume un API de datos Abiertos, pagina publica en la cual encontramos distintos set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The `Connection_DatosAbiertos` function is a Python function that connects to a specified URL and retrieves data from an API.\n",
    "def Connection_DatosAbiertos(star,end, url):\n",
    "    all_data = []\n",
    "    start = f\"{star}T00:00:00\"\n",
    "    end = f\"{end}T23:59:59\"\n",
    "    params = {\n",
    "    \"$limit\": 10000000,\n",
    "    \"$offset\": 0,\n",
    "    \"$where\": f\"fecha_corte >= '{start}' and fecha_corte <='{end}'\"\n",
    "    }\n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            response.raise_for_status()  # Check for any errors in the response\n",
    "            data = response.json()  # Convert the response to JSON format\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            data = []\n",
    "\n",
    "        if not data:  # No more data to fetch, break out of the loop\n",
    "            break\n",
    "        all_data.extend(data)\n",
    "        params[\"$offset\"] += len(data)  # Move the offset for the next request\n",
    "    df = pd.DataFrame(all_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The code defines a function called `date_proc` that takes two parameters: `date_sys` and `days_`.\n",
    "def date_proc(date_sys,days_):\n",
    "    List_days = []\n",
    "    list_weekend = []\n",
    "    contador =1\n",
    "    while len(List_days)<days_:\n",
    "        if (date_sys - timedelta(days=contador)).weekday()==5 or (date_sys - timedelta(days=contador)).weekday()==6:\n",
    "            list_weekend.append(date_sys - timedelta(days=contador))\n",
    "        elif (date_sys - timedelta(days=contador)) in holydays:\n",
    "            list_weekend.append(date_sys - timedelta(days=contador))\n",
    "        else:\n",
    "            List_days.append(date_sys - timedelta(days=contador))\n",
    "        contador = contador + 1\n",
    "    return min(List_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The code snippet is calculating the start and end dates based on the current date.\n",
    "date_prod_i = date_proc(datetime.now(),2)\n",
    "date_prod_f = date_proc(datetime.now(),3)\n",
    "\n",
    "if (date_prod_i -date_prod_f).days >1:\n",
    "    star = (date_prod_f +timedelta(days=1))\n",
    "    end = date_prod_i\n",
    "else:\n",
    "    star = date_prod_i\n",
    "    end = date_prod_i\n",
    "\n",
    "star = date(star.year,star.month,star.day).strftime('%Y-%m-%d')\n",
    "end = date(end.year,end.month,end.day).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.datos.gov.co/resource/qhpu-8ixx.json\"\n",
    "hosttd=\"11.11.11.111\"  #hostname \n",
    "userdb=\"---_------\" #usuario de base de datos\n",
    "pss = '----_------'\n",
    "query = f\"\"\"SELECT\n",
    "    campo1,\n",
    "    campo2\n",
    "    from (select \n",
    "            campo1,\n",
    "            campo2,\n",
    "            campo3\n",
    "        From Tabla1\n",
    "        where campo1 in (1,2,3))as Tbl t inner join Tabla2 b\n",
    "    on t.campo1 = b.campo1\n",
    "    and campo2 = b.campo2\n",
    "    where \n",
    "    t.campo between '{star}' and '{end}'\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Teradata = Connection_TeraData(hosttd,userdb,pss,query)\n",
    "logging.info(f\"Cargue exitoso de informacion TeraData\")\n",
    "df_datosAbiertos = Connection_DatosAbiertos(star,end,url)\n",
    "logging.info(f\"Cargue exitoso de informacion de Datos Abiertos\")\n",
    "logging.info(f\"Fecha Proceso: {datetime.now()}\")\n",
    "logging.info(f\"Fecha Corte  : {star}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_datosAbiertos.shape[0]==0:\n",
    "    logging.warning(f\"No hay datos Cargados para la fecha de corte {star}\")\n",
    "    logging.warning(f\"Finaliza Proceso\")\n",
    "    sys.exit()\n",
    "else:\n",
    "    Columns_df = list(df_datosAbiertos.columns)\n",
    "    Columns_TeraData = list(df_Teradata.columns)\n",
    "\n",
    "    Columns_df_m = []\n",
    "    Columns_TeraDta_m = []\n",
    "\n",
    "    for i in Columns_df:\n",
    "        Columns_df_m.append(i.lower())\n",
    "\n",
    "    for i in Columns_TeraData:\n",
    "        Columns_TeraDta_m.append(i.lower())\n",
    "\n",
    "    df_datosAbiertos.columns = Columns_df_m\n",
    "    df_Teradata.columns = Columns_TeraDta_m\n",
    "\n",
    "    Change_dtypes_TeraData= {\n",
    "    \n",
    "    \"campo1\":\"uint16\",\n",
    "    \"campo2\":\"category\",\n",
    "    \"Campo3\":\"category\",\n",
    "    \"Campo4\":\"category\",\n",
    "    \"Campo5\":\"uint8\",\n",
    "    \"Campo6\":\"object\",\n",
    "    \"Campo7\":\"uint16\",\n",
    "    \"Campo8\":\"uint8\",\n",
    "    \"Campo9\":\"object\",\n",
    "    \"Campo0\":\"uint8\",\n",
    "    \"Campo10\":\"category\",\n",
    "    \"Campo11\":\"category\",\n",
    "    \"Campo12\":\"category\",\n",
    "    \"Campo13\":\"uint8\",\n",
    "    \"Campo14\":\"category\",\n",
    "    \"Campo15\":\"uint8\",\n",
    "    \"Campo16\":\"category\",\n",
    "    \"Campo17\":\"category\",\n",
    "    \"Campo18\":\"uint32\",\n",
    "    \"Campo19\":\"object\",\n",
    "    \"Campo20\":\"uint8\",\n",
    "    \"Campo21\":\"uint16\",\n",
    "    \"Campo22\":\"category\"\n",
    "    }\n",
    "\n",
    "    Change_dtypes_DatosAbiertos = {\n",
    "    \"tipo_entidad\":\"category\",\n",
    "    \"nombre_tipo_entidad\":\"category\",\n",
    "    \"codigo_entidad\":\"uint8\",\n",
    "    \"nombre_entidad\":\"object\",\n",
    "    \"tipo_negocio\":\"uint8\",\n",
    "    \"nombre_tipo_patrimonio\":\"object\",\n",
    "    \"subtipo_negocio\":\"uint8\",\n",
    "    \"nombre_subtipo_patrimonio\":\"category\",\n",
    "    \"codigo_negocio\":\"uint32\",\n",
    "    \"nombre_patrimonio\":\"object\",\n",
    "    \"principal_compartimento\":\"uint8\",\n",
    "    \"tipo_participacion\":\"uint16\"\n",
    "\n",
    "    }\n",
    "\n",
    "    df_Teradata.campo1 = pd.to_datetime(df_Teradata.campo1, format='%d/%m/%Y')\n",
    "    df_datosAbiertos.fecha_corte = pd.to_datetime(df_datosAbiertos.fecha_corte)#, format='%d/%m/%Y')\n",
    "    df_Teradata.campo10 = pd.to_datetime(df_Teradata.campo10,format = '%d/%m/%Y')\n",
    "\n",
    "    for i in Change_dtypes_DatosAbiertos.keys():\n",
    "        df_datosAbiertos[i.lower()] = df_datosAbiertos[i].astype(Change_dtypes_DatosAbiertos[i])\n",
    "\n",
    "\n",
    "    for i in Change_dtypes_TeraData.keys():\n",
    "        df_Teradata[i] = df_Teradata[i].astype(Change_dtypes_TeraData[i])\n",
    "\n",
    "    base_date = datetime(1900, 1, 1)\n",
    "\n",
    "    def fecha_a_numero_serie(fecha):\n",
    "        diferencia = (fecha - base_date).days\n",
    "        return diferencia+2\n",
    "\n",
    "    df_Teradata[\"Mes\"] = (df_Teradata[\"campo1\"].dt.month).astype(\"uint8\")\n",
    "    df_Teradata[\"Anho\"] = (df_Teradata[\"campo1\"].dt.year).astype(\"uint16\")\n",
    "    df_Teradata[\"Fecha_num\"] = (df_Teradata[\"campo1\"].apply(fecha_a_numero_serie)).astype(\"uint16\")\n",
    "    df_Teradata[\"fecha_corte\"] = df_Teradata[\"campo1\"].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "    df_datosAbiertos[\"Mes\"] = df_datosAbiertos.fecha_corte.dt.month\n",
    "    df_datosAbiertos[\"Anho\"] = df_datosAbiertos.fecha_corte.dt.year\n",
    "    df_datosAbiertos[\"Mes\"] = df_datosAbiertos[\"Mes\"].astype(\"uint8\")\n",
    "    df_datosAbiertos[\"Anho\"] = df_datosAbiertos[\"Anho\"].astype(\"uint16\")\n",
    "    df_datosAbiertos[\"Fecha_num\"] = (df_datosAbiertos[\"fecha_corte\"].apply(fecha_a_numero_serie)).astype(\"uint16\")\n",
    "    df_datosAbiertos[\"Fecha_num\"] = df_datosAbiertos[\"Fecha_num\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos los DataFrame con la primary Key para realizar el cruce correspondiente\n",
    "Df_T = df_Teradata[['Key',\"fecha_corte\"]]\n",
    "Df_D = df_datosAbiertos[['Key','fecha_corte']]\n",
    "\n",
    "#realizamos el cruce correspondiente entre los Dataframe para evidenciar lo que se esta registrado en TeraData y no esta en Datos Abiertos\n",
    "TDTA_vs_DA = pd.merge(left = Df_T,\n",
    "                         right = Df_D, \n",
    "                         on='Key', \n",
    "                         how='left',\n",
    "                         suffixes = ('_T','_DA'))\n",
    "\n",
    "#realizamos el cruce correspondiente entre los Dataframe para evidenciar lo que se esta registrado en Datos Abiertos y no esta en TeraData\n",
    "DA_vs_TDTA = pd.merge(left =Df_T,\n",
    "                         right = Df_D, \n",
    "                         on='Key', \n",
    "                         how='right',\n",
    "                         suffixes = ('_DA','_T'))\n",
    "\n",
    "#filtramos los resultados por los datos nulos\n",
    "TDTA_vs_DA = TDTA_vs_DA[TDTA_vs_DA['fecha_corte_DA'].isnull()]\n",
    "DA_vs_TDTA = DA_vs_TDTA[DA_vs_TDTA[\"fecha_corte_T\"].isnull()]\n",
    "\n",
    "#eliminamos los campos de fecha para solo dejar la llave primaria \n",
    "TDTA_vs_DA = TDTA_vs_DA.drop(columns = ['fecha_corte_DA','fecha_corte_T'])\n",
    "DA_vs_TDTA = DA_vs_TDTA.drop(columns = ['fecha_corte_DA','fecha_corte_T'])\n",
    "\n",
    "#cruazamos los resultados con las tablas originales para crear las tablas de salida\n",
    "df_sin_trasmitir_DA = pd.merge(left = df_Teradata,\n",
    "                         right = TDTA_vs_DA, \n",
    "                         on='Key', \n",
    "                         how='inner',\n",
    "                         suffixes = ('_T','_C'))\n",
    "\n",
    "df_sin_trasmitir_TD = pd.merge(left = df_datosAbiertos,\n",
    "                         right = DA_vs_TDTA, \n",
    "                         on='Key', \n",
    "                         how='inner',\n",
    "                         suffixes = ('_DA','_C'))\n",
    "#Creamos la columna en la cual se ejecuta el proceso \n",
    "df_sin_trasmitir_DA[\"Fecha_proceso\"] = datetime.now()\n",
    "df_sin_trasmitir_TD[\"Fecha_Proceso\"] = datetime.now()\n",
    "\n",
    "logging.info(f'Registros en TeraData y no cargados en Datos Abiertos {df_sin_trasmitir_DA.shape[0]}')\n",
    "logging.info(f'Registros en Datos Abiertos y no Registrados en TeraData {df_sin_trasmitir_DA.shape[0]}')\n",
    "#exportamos los datos a un txt\n",
    "NombreArchivo1 = ruta_carpeta+'\\\\'+ mes + dia + str(datetime.now().year) +'_Incremetal_sin_trasmitir_DatosAbiertos.txt' \n",
    "NombreArchivo2 = ruta_carpeta+'\\\\'+ mes + dia + str(datetime.now().year) +'_Incremetal_sin_registro_TeraData.txt'\n",
    "logging.info(f'Archivo con diferencias se ejecto correctamente, Nombre del Archivo {NombreArchivo1}')\n",
    "logging.info(f'Archivo con diferencias se ejecto correctamente, Nombre del Archivo {NombreArchivo2}')\n",
    "df_sin_trasmitir_DA.to_csv(NombreArchivo1, sep='|', index=False)\n",
    "df_sin_trasmitir_TD.to_csv(NombreArchivo2, sep='|', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
